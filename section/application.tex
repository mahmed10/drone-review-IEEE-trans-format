\section{Machine learning based Drone application}
\label{applicationsection}
In the last few years, drone technology has grown and flourished on a large scale. Starting from small package delivery, drones are being used for various purposes nowadays. %Evaluation of commercially drone usage is shown in Fig~\ref{applicaitonfig}.
Though the commercial drone industry is new, it is getting a lot of attention and investments in recent years. Various research is going on regarding this purpose. Few are mentioned below.

\subsection{Inspection, Detection and Tracking}
Autonomous infrastructure inspection is one of the popular applications of UAVs. The drone provides us the advantage of frequent construction monitoring facilities with a low maintenance cost, as it can capture large scale aerial images with a very less amount of human intervention.
A transfer learning-based has developed for crack detection~\cite{kucuksubasi2018transfer}.  Their system can also navigate autonomously in a GPS denied enviornment. They have used RGB and LIDAR cameras for environment detection, and an onboard IMU sensor to detect the velocity of the drone. They have developed an open-source software for moving strategies of the drone. For crack detection, they finetuned different architecture of the CNN model. Among them, InceptionV3 has performed better than others.
In another system the UAV operates autonomously using an ultrasonic beacon system instead of GPS~\cite{kang2018autonomous}. In this research, they developed a ground system that detects the position data from a beacon data using an extended Kalman filter 3 (EKF3) algorithm \cite{willner1976kalman}. This position data is fed to the PID system, which controls the UAV. For crack detection, this system has used CNN with a sliding window technique \cite{cha2017deep}.

Another domain of inspection is road or pavement monitoring. In the CNN and RNN based pavement monitoring system~\cite{wu2018coupling}, they have detected the crack of the pavement using different CNN models, such as Faster Regional-CNN \cite{ren2015faster}, YOLO \cite{redmon2016you}, and Single Shot Multi-Box Detector (SSD) \cite{liu2016ssd}. The output of the model is the rating of the pavement condition, which is fed to an RNN to model to identify the location information. They have used RGB and IR thermal camera.
Transformed image can also be used instead of raw image for road inspection~\cite{fan2019real}. In that research they have converted the perspective view into reference view. Their whole work is divided into three part: perspective transformation (converting image same as reference), dense road stereo (cost computation with reference), and finally disparity transformation. Using this algorithm results in computational complexity reduction of the algorithm and disparity accuracy improvement. 

For most of the drone-based detection case, most of the researcher works on static objects. Very few research explored the model of motion. For this purpose, a benchmark dataset was constructed consisting of 70 videos~\cite{li2017visual}. They have introduced a new camera motion $\mathbf{H}_{t}$ term is in the motion model $\mathbf{z}_{t}=\mathbf{H}_{t} \mathbf{z}_{t-1}+\Delta \mathbf{z}_{t}$. As a baseline of the tracking system, they used the following methods: three types of correlation filter approaches (KCF~\cite{henriques2014high}, DSST~\cite{danelljan2014accurate}, SRDCF~\cite{danelljan2015learning}), color-based discriminatory tracker (DAT~\cite{possegger2015defense}); approach based on a competitive particle filter (HOGLR~\cite{wang2015understanding}); ensemble technique (MEEM~\cite{zhang2014meem}); and two approaches, based on deep learning (SODLT~\cite{wang2015transferring}, MDNet~\cite{nam2016learning}). Several other methods were proposed to detect and track a UAV using another UAV. For example, YOLOv3 and YOLOv3-Tiny models had been utilized for detection purpose~\cite{saribas2019hybrid}. Their main contribution is introducing a kernelized  correlation filter which improves the detection result. 

The analysis of videos captured by drones for the extraction of useful information is complicated because of the presence of small items, changes in viewpoints of these items, changes in lighting, large-scale video resolution, occlusion, and truncation. To overcome these challenges, a processing pipeline  was proposed integrating DeForm convolution layers in the backbone~\cite{zhang2019dense}.

\subsection{Disaster Management, Rescue System, and Supply Chain}
A drone can be an efficient tool in case of a rescue mission. Rescue programs are often involved in remote operations, treating the sick, or searching for missing people. Time is an essential factor in making search and rescue missions a positive outcome.  The rescue and search operation of wildlife is more challenging~\cite{mayer2019drones}. According to the research~\cite{brennan2019drones}, in case of these operations, the model should have few qualities, E.g., guidance and navigation; collaborative search and inspection; physically handling materials.
SPOT (Systematic Poacher Detector) which increases the capacity of drones to automatically identify poachers and animals in near real-time~\cite{bondi2018spot}.  SPOT uses state-of-the-art AI strategies, such as Faster RCNN as the base model, where input is the infrared image.

A framework  was outlined for creating explanations of autonomous system behavior and reasoning~\cite{garcia2018explainable}. They focused on the NLP for explaining incidence. They have named their model as 'speak-aloud,' which can fly to a remote area and alert if any accident occurs. In short, it is a chatbot that will not only describe the incident but also can reply to the different questions of users on that incident. For a vehicle spiraling incident, if a user asks why it is doing like this, the system will respond with the reason behind that (E.g., GPS fixing or transmitting to safe plane depth).

A autonomous drone can monitor a area and detect various calamities like flood, fire, collapsed building~\cite{kyrkou2019deep}. They have introduced a Aerial Image Database for Emergency Response application which is named as AIDER. Based on the analysis of the database, they have built a light weight CNN architecture on a embedded device.
Another system namely ``DronAID'' is capable of identifying people in desperate circumstances~\cite{tariq2018dronaid}. They have detected humans using a PIR sensor of the drone. According to the \cite{jin2011target}, a human body radiates IR at a certain wavelength. Besides detecting humans, this DronAID can also telecast a live stream and provide the location of the trapped person to the rescue team. 

The supply chain is a sequential process that is associated with the production and distribution of commercial goods. Nowadays, UAVs have a lot of applications in autonomous supply chain management. An image processing system has been introduced that can classify, quantify the number of citrus fruits from every single tree of a garden~\cite{apolo2020deep}. It can also predict the shape of each fruit using deep learning. They have used a Faster R-CNN Deep Learning model to detect orange. They have also used an LSTM model to predict the possible number of orange in advance. They conducted this experiment on 20 trees for three consecutive years.

A company needs to keep track of its stock to succeed in the market. For this purpose, a drone can be used to perform a periodic inventory check and determine whether to purchase more supplies. According to the concept of Industry 4.0, a drone-based system has been developed to automate inventory stuff and keep the record of products assigned by the RFID tags~\cite{fernandez2019towards}. The framework uses a blockchain and a distributed ledger to store and verify all product data obtained by the drone. 